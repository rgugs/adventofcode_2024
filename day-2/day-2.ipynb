{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste input data into csv file and read into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>73.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4     5     6     7\n",
       "0    22  25  27  28  30  31.0  32.0  29.0\n",
       "1    72  74  75  77  80  81.0  81.0   NaN\n",
       "2    52  53  55  58  59  63.0   NaN   NaN\n",
       "3    14  17  19  22  27   NaN   NaN   NaN\n",
       "4    65  68  67  68  71  73.0  76.0  77.0\n",
       "..   ..  ..  ..  ..  ..   ...   ...   ...\n",
       "995  43  46  49  52  55  56.0  57.0  58.0\n",
       "996  41  44  47  48  50  53.0   NaN   NaN\n",
       "997  33  31  28  27  24  22.0  19.0   NaN\n",
       "998  36  35  32  31  28   NaN   NaN   NaN\n",
       "999  93  91  90  89  86  85.0  82.0  80.0\n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input-day2.csv', sep=' ', header=None, engine='python',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through rows and drop NaN values then use .is_monotonic_increasing and .is_monotonic_decreasing with .is_unique to check for strict increasing/decreasing to check the first rule.\n",
    "If the series passes the first test, check if all absolute values in the series are less than 4. (The strict monotonic check already filtered out any values with a difference of less than 1.)\n",
    "\n",
    "*I feel like there may be a way to do this in a vectorized way, maybe with apply, but I wasn't sure how to do the extra data cleaning for the processing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list = []\n",
    "for idx, row in df.iterrows():\n",
    "    p1 = row.dropna()\n",
    "    if (p1.is_monotonic_increasing and p1.is_unique) or (p1.is_monotonic_decreasing and p1.is_unique):\n",
    "        clean = p1.diff().dropna().astype('int').abs()\n",
    "        if clean.lt(4).all():\n",
    "            clean_list.append(clean)\n",
    "\n",
    "solution_p1 = len(clean_list)\n",
    "solution_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Problem Dampener is a reactor-mounted module that lets the reactor safety systems tolerate a single bad level in what would otherwise be a safe report. It's like the bad level never happened! Now, the same rules apply as before, except if removing a single level from an unsafe report would make it safe, the report instead counts as safe. Update your analysis by handling situations where the Problem Dampener can remove a single level from unsafe reports. How many reports are now safe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the same steps as above, but append all the unsafe reports to a list for this part. \n",
    "\n",
    "Try:\n",
    "- [X] Groupby then counter to count how many groups are >= 2 counts, if counter is more than 1, it fails\n",
    "- [ ] Create df of series, column of diffs, and if diff is +/-/0 \n",
    "- [ ] monotonic without unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n"
     ]
    }
   ],
   "source": [
    "# Reconfigure Part 1 solution\n",
    "def check_strict_safe(input_df):\n",
    "    ''' Strict check on safe reports ignoring the Problem Dampener.\n",
    "        Input is Pandas df made from csv.\n",
    "        Checks for strict increasing or decreasing numbers and the difference between all values is less than 4.\n",
    "        Returns 2 lists of Pandas series, Strictly Safe and Possibly Unsafe.\n",
    "    '''\n",
    "    strict_safe_list = []\n",
    "    unsafe_list = []\n",
    "    for idx, row in input_df.iterrows():\n",
    "        p1 = row.dropna()\n",
    "        # Checks for strict increasing or decreasing values in series and writes to associated list\n",
    "        if (p1.is_monotonic_increasing and p1.is_unique) or (p1.is_monotonic_decreasing and p1.is_unique):\n",
    "            clean = p1.diff().dropna().astype('int').abs()\n",
    "            # Only add series where all diff values are under 4 to safe list\n",
    "            if clean.lt(4).all():\n",
    "                strict_safe_list.append(clean)\n",
    "            else:\n",
    "                unsafe_list.append(p1)\n",
    "        else:\n",
    "            unsafe_list.append(p1)\n",
    "    return strict_safe_list , unsafe_list\n",
    "\n",
    "strict_safe_list, unsafe_list = check_strict_safe(df)\n",
    "print(len(unsafe_list)) # Checking I captured all the unsafe reports (Should be 361 (1000 - 639)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks Strict safety - Run after any cleaning operation, and if False, add it to the rejected list\n",
    "def is_strict_safe(input_series):\n",
    "    clean = input_series.dropna()\n",
    "    if ((clean.is_monotonic_increasing and clean.is_unique) or (clean.is_monotonic_decreasing and clean.is_unique)):\n",
    "        clean2 = clean.diff().dropna().astype('int').abs()\n",
    "        if clean2.lt(4).all():\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False\n",
    "\n",
    "# Checks for Duplicate Values greater or equal to 3\n",
    "def num_dup_values_check(input_series):\n",
    "    grouped = input_series.groupby(input_series).count()\n",
    "    if grouped.ge(3).any():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Checks for multiple sets of Duplicate Values\n",
    "def mult_dup_values_check(input_series):\n",
    "    grouped = input_series.groupby(input_series).count()\n",
    "    counter = 0\n",
    "    for i in grouped:\n",
    "        if i == 2:\n",
    "            counter += 1\n",
    "    if counter > 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "# Check for more than a single abs(diff) value over 3\n",
    "def num_diff_values(input_series):\n",
    "    diffed = input_series.diff().dropna().astype('int').abs()\n",
    "    counter = 0\n",
    "    for i in diffed:\n",
    "        if i > 3:\n",
    "            counter += 1\n",
    "    if counter > 1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Check for multiple changes in trend slope direction\n",
    "def slope_direction_changes(input_series):\n",
    "    df = pd.DataFrame({'values' : input_series, 'diffs' : input_series.diff(), 'signs' : np.sign(input_series.diff())})\n",
    "    signs = df['signs'].groupby(df['signs']).count()\n",
    "    length = len(signs)\n",
    "    if length > 2:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    }
   ],
   "source": [
    "check_1 = []\n",
    "rejected = []\n",
    "for record in unsafe_list:\n",
    "    if num_dup_values_check(record):\n",
    "        check_1.append(record)\n",
    "    else:\n",
    "        rejected.append(record)\n",
    "\n",
    "print(len(check_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "check_2 = []\n",
    "for record in check_1:\n",
    "    if mult_dup_values_check(record):\n",
    "        check_2.append(record)\n",
    "    else:\n",
    "        rejected.append(record)\n",
    "\n",
    "print(len(check_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "check_3 = []\n",
    "for record in check_2:\n",
    "    if num_diff_values(record):\n",
    "        check_3.append(record)\n",
    "    else:\n",
    "        rejected.append(record)\n",
    "\n",
    "print(len(check_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "check_4 = []\n",
    "for record in check_3:\n",
    "    if slope_direction_changes(record):\n",
    "        check_4.append(record)\n",
    "    else:\n",
    "        rejected.append(record)\n",
    "print(len(check_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Situations to check\n",
    "\n",
    "Immediate disqualification\n",
    "- Duplicate value groups > 2\n",
    "- Duplicate values over 2. (Groupby('value').any() count is >= 3)\n",
    "- More than 1 diff value abs(>= 4)\n",
    "- 3 groups after groupby('signs')\n",
    "\n",
    "Requires additional checks\n",
    "- Single set of duplicated values - Increase error count for df\n",
    "- Single diff value >= 4 - Increase error count (Will need to remove value and rerun diff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aoc-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
